{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AWi68Da6rKJb",
        "outputId": "45aac624-1e78-4d8f-f759-789cd131192e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Suitability as prospective Customers [20 60 30 60 60 30 20 90 40 40 20 30 90 40 90 30 40 40 60 40 60 20 90 20\n",
            " 60 60 90 60 40 60 20 30 60 40 30 90 90 40]\n",
            "Model accuracy: 0.9473684210526315\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "import pickle\n",
        "\n",
        "# Load the dataset\n",
        "df = pd.read_csv('/content/final - Sheet1 (1).csv')\n",
        "\n",
        "# Convert text features to numerical values\n",
        "le = LabelEncoder()\n",
        "df['mobile_phone'] = le.fit_transform(df['mobile_phone'])\n",
        "df['mobile_brand'] = le.fit_transform(df['mobile_brand'])\n",
        "df['location'] = le.fit_transform(df['location'])\n",
        "df['payee'] = le.fit_transform(df['payee'])\n",
        "df['monthly_total_transaction'] = le.fit_transform(df['monthly_total_transaction'])\n",
        "df.drop('name', axis=1, inplace=True)\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X = df.drop('prospective', axis=1)\n",
        "y = df['prospective']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Build the Random Forest model\n",
        "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "rf.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred = rf.predict(X_test)\n",
        "print('Suitability as prospective Customers', y_pred)\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print('Model accuracy:', accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "filename = 'rf.pkl'\n",
        "with open(filename, 'wb') as file:\n",
        "    pickle.dump(rf, file)"
      ],
      "metadata": {
        "id": "M-hCM67U5C3l"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "82DFR0044-SH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "import pickle\n",
        "# Load the dataset\n",
        "df = pd.read_csv('/content/final - Sheet1 (1).csv')\n",
        "\n",
        "# Convert text features to numerical values\n",
        "le = LabelEncoder()\n",
        "df['mobile_phone'] = le.fit_transform(df['mobile_phone'])\n",
        "df['mobile_brand'] = le.fit_transform(df['mobile_brand'])\n",
        "df['location'] = le.fit_transform(df['location'])\n",
        "df['payee'] = le.fit_transform(df['payee'])\n",
        "df['monthly_total_transaction'] = le.fit_transform(df['monthly_total_transaction'])\n",
        "df.drop('name', axis=1, inplace=True)\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X = df.drop('prospective', axis=1)\n",
        "y = df['prospective']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Build the logistic regression model\n",
        "lr = LogisticRegression(random_state=42)\n",
        "lr.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred = lr.predict(X_test)\n",
        "\n",
        "# Evaluate the model's accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print('Model accuracy:', accuracy)\n",
        "print(y_pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HTGKWQJ9zg_g",
        "outputId": "364f05b6-1096-4fea-d6e8-a5e80bf6f518"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model accuracy: 0.868421052631579\n",
            "[20 60 40 60 60 30 20 90 40 40 20 40 90 40 90 30 40 40 60 40 60 20 90 20\n",
            " 60 60 90 60 40 60 20 30 60 40 40 90 90 40]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "filename = 'lr.pkl'\n",
        "with open(filename, 'wb') as file:\n",
        "    pickle.dump(lr, file)"
      ],
      "metadata": {
        "id": "1RgAWoX04U3q"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import silhouette_score\n",
        "import matplotlib.pyplot as plt\n",
        "import pickle\n",
        "# Load the dataset\n",
        "df = pd.read_csv('/content/final - Sheet1 (1).csv')\n",
        "\n",
        "# Convert text features to numerical values\n",
        "\n",
        "le = LabelEncoder()\n",
        "df['mobile_phone'] = le.fit_transform(df['mobile_phone'])\n",
        "df['mobile_brand'] = le.fit_transform(df['mobile_brand'])\n",
        "df['location'] = le.fit_transform(df['location'])\n",
        "df['payee'] = le.fit_transform(df['payee'])\n",
        "df['monthly_total_transaction'] = le.fit_transform(df['monthly_total_transaction'])\n",
        "df.drop('name', axis=1, inplace=True)\n",
        "\n",
        "# Select the features for clustering\n",
        "X = df[['monthly_total_transaction', 'mobile_phone', 'mobile_brand', 'payee', 'location', 'prospective']]\n",
        "\n",
        "# Find the optimal number of clusters using the elbow method\n",
        "wcss = []\n",
        "for i in range(1, 11):\n",
        "    kmeans = KMeans(n_clusters=i, init='k-means++', max_iter=300, n_init=10, random_state=42)\n",
        "    kmeans.fit(X)\n",
        "    wcss.append(kmeans.inertia_)\n",
        "\n",
        "\n",
        "# Build the K-means clustering model\n",
        "kmeans = KMeans(n_clusters=3, init='k-means++', max_iter=300, n_init=10, random_state=42)\n",
        "kmeans.fit(X)\n",
        "\n",
        "# Assign clusters to the data points\n",
        "y_pred = kmeans.predict(X)\n",
        "\n",
        "# Evaluate the model's performance using silhouette score\n",
        "silhouette_avg = silhouette_score(X, y_pred)\n",
        "print('Silhouette score:', silhouette_avg)\n",
        "print(y_pred)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zax2mul90wdR",
        "outputId": "7d591ef5-b27b-4cd0-9779-25283d10d8b6"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Silhouette score: 0.7630805599317536\n",
            "[2 2 2 2 2 2 2 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2\n",
            " 2 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 0 0 0 0 0\n",
            " 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 0 0 0 0 0 0 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 2 2 2 2 2 2 2 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "filename = 'kmeans.pkl'\n",
        "with open(filename, 'wb') as file:\n",
        "    pickle.dump(kmeans, file)"
      ],
      "metadata": {
        "id": "S7mEwrbA5KPM"
      },
      "execution_count": 62,
      "outputs": []
    }
  ]
}